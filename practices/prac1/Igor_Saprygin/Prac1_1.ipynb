{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# RL basics\n",
        "\n",
        "Термины и понятия:\n",
        "\n",
        "- агент/среда\n",
        "- наблюдение $o$ / состояние $s$\n",
        "- действие $a$, стратегия $\\pi: \\pi(s) \\rightarrow a$ функция перехода $T: T(s, a) \\rightarrow s'$\n",
        "- вознаграждение $r$, ф-я вознаграждений $R: R(s, a) \\rightarrow r$\n",
        "- цикл взаимодействия, траектория $\\tau: (s_0, a_0, r_0, s_1, a_1, r_1, ..., s_T, a_T, r_T)$, эпизод\n",
        "- отдача $G$, подсчет отдачи, средняя[/ожидаемая] отдача $\\mathbb{E}[G]$"
      ],
      "metadata": {
        "id": "k4NMHBq16Y_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    COLAB = True\n",
        "except ModuleNotFoundError:\n",
        "    COLAB = False\n",
        "    pass\n",
        "\n",
        "if COLAB:\n",
        "    !pip -q install \"gymnasium[classic-control, atari, accept-rom-license]\"\n",
        "    !pip -q install piglet\n",
        "    !pip -q install imageio_ffmpeg\n",
        "    !pip -q install moviepy==1.0.3"
      ],
      "metadata": {
        "id": "MoNP7Wdn6aP0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a09de8-c545-4b17-9758-1fd98c8115ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: gymnasium 1.2.0 does not provide the extra 'accept-rom-license'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "9JPaLF5v6esZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent, environment\n",
        "\n",
        "<img src=https://gymnasium.farama.org/_images/lunar_lander.gif caption=\"lunar lander\" width=\"150\" height=\"50\"><img src=https://gymnasium.farama.org/_images/mountain_car.gif caption=\"mountain car\" width=\"150\" height=\"50\">\n",
        "<img src=https://gymnasium.farama.org/_images/cliff_walking.gif caption=\"cliff walking\" width=\"300\" height=\"50\">\n",
        "<img src=https://ale.farama.org/_images/montezuma_revenge.gif caption=\"montezuma revenge\" width=\"150\" height=\"100\">\n",
        "<img src=https://github.com/danijar/crafter/raw/main/media/video.gif caption=\"crafter\" width=\"150\" height=\"100\">\n",
        "<img src=https://camo.githubusercontent.com/6df2ca438d8fe8aa7a132b859315147818c54af608f8609320c3c20e938acf48/68747470733a2f2f6d656469612e67697068792e636f6d2f6d656469612f344e78376759694d394e44724d724d616f372f67697068792e676966 caption=\"malmo minecraft\" width=\"150\" height=\"100\">\n",
        "<img src=https://images.ctfassets.net/kftzwdyauwt9/e0c0947f-1a44-4528-4a41450a9f0a/2d0e85871d58d02dbe01b2469d693d4a/table-03.gif caption=\"roboschool\" width=\"150\" height=\"100\">\n",
        "<img src=https://raw.githubusercontent.com/Tviskaron/mipt/master/2019/RL/02/mdp.png caption=\"Марковский процесс принятия решений\" width=\"150\" height=\"100\">\n",
        "<img src=https://minigrid.farama.org/_images/DoorKeyEnv.gif caption=\"minigrid\" width=\"120\" height=\"120\">"
      ],
      "metadata": {
        "id": "OGAoJeNF6hJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observation, state\n",
        "\n",
        "TODO:\n",
        "- добавить примеры наблюдений/состояний (числа, векторы, картинки)\n",
        "- интуитивное объяснение различия, положить пока, что наблюдение = состояние\n",
        "- пространство состояний\n",
        "\n",
        "\n",
        "В каждый момент времени среда имеет некоторое внутреннее состояние. Здесь слово \"состояние\" я употребил скорее в интуитивном понимании, чтобы обозначить, что среда изменчива (иначе какой смысл с ней взаимодействовать, если ничего не меняется). В обучении с подкреплением под термином состояние $s$ (или $s_t$, где $t$ — текущее время) подразумевают либо абстрактно информацию о \"состоянии\" среды, либо ее явное представление в виде данных, достаточные для полного описания \"состояния\". *NB: Здесь можно провести аналогию с компьютерными играми — файл сохранения игры как раз содержит информацию о \"состоянии\" мира игры, чтобы в будущем можно было продолжить с текущей точки, так что данные этого файла в целом можно с некоторой натяжкой считать состоянием (с натяжкой, потому что редко когда в сложных играх файлы сохранения содержат прямо вот всю информацию, так что после перезагрузки вы получите не совсем точную копию). При этом обычно подразумевается, что состояние не содержит в себе ничего лишнего, то есть это **минимальный** набор информации.*\n",
        "\n",
        "Наблюдением $o$ называют то, что агент \"видит\" о текущем состоянии среды. Это не обязательно зрение, а вообще вся доступная ему информация (условно, со всех его органов чувств).\n",
        "\n",
        "В общем случае наблюдение: кортеж/словарь многомерных векторов чисел."
      ],
      "metadata": {
        "id": "dcyLKga76mA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(gym.make(\"CartPole-v0\").reset()[0].shape)\n",
        "print(gym.make(\"MountainCar-v0\").reset()[0].shape)"
      ],
      "metadata": {
        "id": "ypHv9w6i6pcX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f0deba9-8469-403b-8aea-c3d582bf983a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n",
            "(2,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/envs/registration.py:512: DeprecationWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.deprecation(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Action, policy, transition function\n",
        "\n",
        "Рассмотрим следующие MDP:\n",
        "\n",
        "- A: <img src=https://i.ibb.co/mrCMVZLQ/mdp-a.png caption=\"A\" width=\"400\" height=\"100\">\n",
        "- B: <img src=https://i.ibb.co/GQ2tVtjC/mdp-b.png caption=\"B\" width=\"400\" height=\"100\">\n",
        "\n",
        "Links to all:\n",
        "[A](https://i.ibb.co/mrCMVZLQ/mdp-a.png)\n",
        "[B](https://i.ibb.co/GQ2tVtjC/mdp-b.png)\n",
        "[C](https://i.ibb.co/Jj9LYHjP/mdp-c.png)\n",
        "[D](https://i.ibb.co/Y47Mr83b/mdp-d.png)\n",
        "[E](https://i.ibb.co/Kjt1Xhmf/mdp-e.png)\n",
        "\n",
        "Давайте явно запишем пространства состояний $S$ и действий $A$, а также функцию перехода $T$ среды."
      ],
      "metadata": {
        "id": "GabuCLcJ67lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_states = set(range(3))\n",
        "A_actions = set(range(1))\n",
        "\n",
        "print(f'{A_states=} | {A_actions=}')\n",
        "\n",
        "T_A = {\n",
        "    (0, 0): 1,\n",
        "    (1, 0): 2,\n",
        "    (2, 0): 2\n",
        "}\n",
        "print(f'Transition function {T_A=}')\n",
        "\n",
        "A_mdp = A_states, A_actions, T_A"
      ],
      "metadata": {
        "id": "4XpqNc_o6_CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2e6e9f4-00d9-4644-d790-89f31947f833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_states={0, 1, 2} | A_actions={0}\n",
            "Transition function T_A={(0, 0): 1, (1, 0): 2, (2, 0): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуйте записать функцию перехода в матричном виде:"
      ],
      "metadata": {
        "id": "KlqB4WcZ7CDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_mtx = np.zeros((3,3))\n",
        "A_vals = np.array(list(T_A.values()))\n",
        "A_mtx[np.arange(3), A_vals] = 1\n",
        "A_mtx"
      ],
      "metadata": {
        "id": "jmg8hnng7EnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c50c87-162f-4454-b328-e80d897be2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как получить вероятность нахождения агента в состоянии (1) через N шагов? Что происходит с вероятностями нахождения в состояниях при $N \\rightarrow \\infty$"
      ],
      "metadata": {
        "id": "_FPshg_07G0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2\n",
        "An = np.linalg.matrix_power(A_mtx, N)\n",
        "print(An[0,1])\n",
        "N = 1000\n",
        "An = np.linalg.matrix_power(A_mtx, N)\n",
        "print(An[0,1])"
      ],
      "metadata": {
        "id": "9pwc4Atn7IAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a3d016d-635d-4ff3-ae43-0e7027188123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задайте еще несколько MDP:\n",
        "\n",
        "- C: <img src=https://i.ibb.co/Jj9LYHjP/mdp-c.png caption=\"C\" width=\"400\" height=\"100\">"
      ],
      "metadata": {
        "id": "p52R04np7Ku0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B_states = set(range(4))\n",
        "B_actions = set(range(3))\n",
        "\n",
        "print(f'{B_states=} | {B_actions=}')\n",
        "\n",
        "T_B = {\n",
        "    (0, 0): 1,\n",
        "    (0, 1): 2,\n",
        "    (0, 2): 3\n",
        "}\n",
        "print(f'Transition function {T_B=}')\n",
        "\n",
        "B_mdp = B_states, B_actions, T_B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-inadplcPmo4",
        "outputId": "e8de4902-2e5b-4977-a44c-0cc8f4dde75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B_states={0, 1, 2, 3} | B_actions={0, 1, 2}\n",
            "Transition function T_B={(0, 0): 1, (0, 1): 2, (0, 2): 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B_mtx = np.eye(4)\n",
        "B_mtx[0,0]=0\n",
        "B_vals = np.array(list(T_B.values()))\n",
        "B_mtx[0, B_vals] = 1/3\n",
        "B_mtx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSwn4sD5QgGD",
        "outputId": "6aa31abf-f618-48c6-dc95-6fff8ed45aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.33333333, 0.33333333, 0.33333333],\n",
              "       [0.        , 1.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 1.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2\n",
        "Bn = np.linalg.matrix_power(B_mtx, N)\n",
        "print(Bn[0,1])\n",
        "N = 1000\n",
        "Bn = np.linalg.matrix_power(B_mtx, N)\n",
        "print(Bn[0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADbOMgr4Qavh",
        "outputId": "5157b102-3420-4e0b-9280-265dbccaff8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3333333333333333\n",
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_states = set(range(4))\n",
        "C_actions = set(range(2))\n",
        "\n",
        "print(f'{C_states=} | {C_actions=}')\n",
        "\n",
        "T_C = {\n",
        "    (0, 0): 1,\n",
        "    (0, 1): 2,\n",
        "    (1, 0): 1,\n",
        "    (1, 1): 3,\n",
        "    (2, 0): 3,\n",
        "    (2, 1): 2,\n",
        "}\n",
        "print(f'Transition function {T_C=}')\n",
        "\n",
        "C_mdp = C_states, C_actions, T_C\n"
      ],
      "metadata": {
        "id": "JSdJ9ZsI7Nfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bec0939-3eb3-4a27-d9a1-aa7389791fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C_states={0, 1, 2, 3} | C_actions={0, 1}\n",
            "Transition function T_C={(0, 0): 1, (0, 1): 2, (1, 0): 1, (1, 1): 3, (2, 0): 3, (2, 1): 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_mtx = np.array([[0, 0.5, 0.5, 0],\n",
        "                 [0, 0.5, 0, 0.5],\n",
        "                 [0, 0, 0.5, 0.5],\n",
        "                 [0, 0, 0, 1]])"
      ],
      "metadata": {
        "id": "A4DFIm9APXti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 2\n",
        "Cn = np.linalg.matrix_power(C_mtx, N)\n",
        "print(Cn[0,1])\n",
        "N = 1000\n",
        "Cn = np.linalg.matrix_power(C_mtx, N)\n",
        "print(Bn[0,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIXodw-_Sp5s",
        "outputId": "2039bb36-dc12-4db1-e195-e9430ffe7325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.25\n",
            "0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Давайте попробуем задать двух агентов: случайного и оптимального (для каждой среды свой)."
      ],
      "metadata": {
        "id": "AiU5X4DH7TaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "    def __init__(self, actions):\n",
        "        self.rng = np.random.default_rng()\n",
        "        self.actions = np.array(list(actions))\n",
        "\n",
        "    def act(self, state):\n",
        "        return self.rng.integers(len(self.actions))"
      ],
      "metadata": {
        "id": "It2waXJi7WWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве дополнения, запишите стратегию агента"
      ],
      "metadata": {
        "id": "VH6uo4EP7ZqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Oracle:\n",
        "  def __init__(self, R):\n",
        "    self.R = R\n",
        "  def act(self, state):\n",
        "    best = -np.inf\n",
        "    action = None\n",
        "    for k,v in self.R.items():\n",
        "      if k[0] == state:\n",
        "        if v > best:\n",
        "          best = v\n",
        "          action = k[1]\n",
        "    return action\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t68c_r-W7asH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reward, reward function\n",
        "\n",
        "Теперь добавим произвольную функцию вознаграждения. Например, для A:"
      ],
      "metadata": {
        "id": "XGx2-KeH7lL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_R = {\n",
        "    (0, 0): -0.1,\n",
        "    (1, 0): 1.0,\n",
        "    (2, 0): 0.0\n",
        "}\n",
        "A_terminal = {2}\n",
        "print(A_R)\n",
        "\n",
        "A_mdp = *A_mdp, A_R\n",
        "print(A_mdp)"
      ],
      "metadata": {
        "id": "fk7umEnA7oFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf409b65-078d-41cd-b732-b1faaa688698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 0): -0.1, (1, 0): 1.0, (2, 0): 0.0}\n",
            "({0, 1, 2}, {0}, {(0, 0): 1, (1, 0): 2, (2, 0): 2}, {(0, 0): -0.1, (1, 0): 1.0, (2, 0): 0.0})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B_R = {}\n",
        "B_terminal = {1, 2, 3}\n",
        "for i in B_states:\n",
        "  for j in B_actions:\n",
        "    B_R[(i,j)] = np.random.rand()\n",
        "for el in terminal:\n",
        "  for j in B_actions:\n",
        "    B_R[(i,j)] = 0\n",
        "B_mdp = *B_mdp, B_R\n",
        "B_R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhAVeG2vL9Ld",
        "outputId": "0c32e275-efbb-485f-ea99-edf53831552b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 0.16267142477541396,\n",
              " (0, 1): 0.1473654946226972,\n",
              " (0, 2): 0.7423486725078765,\n",
              " (1, 0): 0.437366814854246,\n",
              " (1, 1): 0.0011258699662193283,\n",
              " (1, 2): 0.8689692617523015,\n",
              " (2, 0): 0.6467428244595352,\n",
              " (2, 1): 0.4996095742476935,\n",
              " (2, 2): 0.5230699661263218,\n",
              " (3, 0): 0,\n",
              " (3, 1): 0,\n",
              " (3, 2): 0}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C_R = {}\n",
        "C_terminal = {3}\n",
        "for i in C_states:\n",
        "  for j in C_actions:\n",
        "    C_R[(i,j)] = np.random.rand()\n",
        "for el in terminal:\n",
        "  for j in C_actions:\n",
        "    C_R[(i,j)] = 0\n",
        "C_mdp = *C_mdp, C_R\n",
        "C_R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0nKNeFbLZqJ",
        "outputId": "597c44b5-db91-4c87-f006-7a48f100e76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 0.9223614885921632,\n",
              " (0, 1): 0.10866944901848874,\n",
              " (1, 0): 0.20208980760882989,\n",
              " (1, 1): 0.43005895623766344,\n",
              " (2, 0): 0.8520765336094754,\n",
              " (2, 1): 0.0007898708196252269,\n",
              " (3, 0): 0,\n",
              " (3, 1): 0}"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interaction loop, trajectory, termination, truncation, episode\n",
        "\n",
        "Общий цикл взаимодействия в рамках эпизода:\n",
        "1. Инициализировать среду: $s \\leftarrow \\text{env.init()}$\n",
        "2. Цикл:\n",
        "    - выбрать действие: $a \\leftarrow \\pi(s)$\n",
        "    - получить ответ от среды: $s, r, d \\leftarrow \\text{env.next(a)}$\n",
        "    - если $d == \\text{True}$, выйти из цикла"
      ],
      "metadata": {
        "id": "j92TZ1l67rVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episode(mdp, agent, terminal, n_steps=10):\n",
        "    states, actions, T, R = mdp\n",
        "    s = 0\n",
        "    tau = []\n",
        "    for _ in range(n_steps):\n",
        "        a = agent.act(s)\n",
        "        s_next = T[(s, a)]\n",
        "        r = R[(s, a)]\n",
        "\n",
        "        tau.append((s, a, r))\n",
        "        s = s_next\n",
        "        if s in terminal:\n",
        "          break\n",
        "\n",
        "    return tau\n",
        "\n",
        "print(run_episode(A_mdp,Agent(A_actions), A_terminal))\n",
        "print(run_episode(A_mdp,Oracle(A_R), A_terminal))"
      ],
      "metadata": {
        "id": "MRPZACJt7vG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcc96f28-7fd6-4da1-e1c7-2890fc7e7a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, np.int64(0), -0.1), (1, np.int64(0), 1.0)]\n",
            "[(0, 0, -0.1), (1, 0, 1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_episode(B_mdp,Agent(B_actions), B_terminal))\n",
        "print(run_episode(B_mdp,Oracle(B_R), B_terminal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v926H2DWy_3",
        "outputId": "34fc99fd-5b5d-4dfb-db4e-4ae95dfc1e53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, np.int64(1), 0.1473654946226972)]\n",
            "[(0, 2, 0.7423486725078765)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_episode(C_mdp,Agent(C_actions), C_terminal))\n",
        "print(run_episode(C_mdp,Agent(C_actions), C_terminal))\n",
        "print(run_episode(C_mdp,Oracle(C_R), C_terminal))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz22Mb93W6Vt",
        "outputId": "43056bb4-8351-47f1-b0d5-3157f0cb6543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, np.int64(0), 0.9223614885921632), (1, np.int64(1), 0.43005895623766344)]\n",
            "[(0, np.int64(1), 0.10866944901848874), (2, np.int64(0), 0.8520765336094754)]\n",
            "[(0, 0, 0.9223614885921632), (1, 1, 0.43005895623766344)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Termination — означает окончание эпизода, когда достигнуто терминальное состояние. Является частью задания среды.\n",
        "\n",
        "Truncation — означает окончание эпизода, когда достигнут лимит по числу шагов (=времени). Обычно является внешне заданным параметром для удобства обучения.\n",
        "\n",
        "Пока не будем вводить truncation, но поддержим termination: расширьте определение среды информацией о терминальных состояниях для всех описанных ранее сред. Сгенерируйте по несколько случайных траекторий для каждой среды."
      ],
      "metadata": {
        "id": "wbGEr8kl7xnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Return, expected return\n",
        "\n",
        "Наиболее важная метрика оценки качества работы агента: отдача.\n",
        "\n",
        "Отдача: $G(s_t) = \\sum_{i=t}^T r_i$\n",
        "\n",
        "Обычно также вводят параметр $\\gamma \\in [0, 1]$, дисконтирующий будущие вознаграждения. А еще, тк отдача может меняться от запуска к запуску благодаря вероятностным процессам, нас интересует отдача в среднем — ожидаемая отдача:\n",
        "\n",
        "$$\\hat{G}(s_t) = \\mathbb{E} [ \\sum_{i=t}^T \\gamma^{i-t} r_i ]$$\n",
        "\n",
        "Именно ее и оптимизируют в RL.\n",
        "\n",
        "Давайте научимся считать отдачу для состояний по траектории и считать среднюю отдачу."
      ],
      "metadata": {
        "id": "lxHNM9kS74WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_G(trajectory):\n",
        "  sum = 0\n",
        "  for step in trajectory:\n",
        "    _, _, r = step\n",
        "    sum += r\n",
        "  return sum\n",
        "\n",
        "def get_mean_G(mdp, terminal, agent, n_trajectories=10):\n",
        "  sum = 0\n",
        "  for i in range(n_trajectories):\n",
        "    trajectory = run_episode(mdp,agent,terminal)\n",
        "    sum += get_G(trajectory)\n",
        "  return sum / n_trajectories\n"
      ],
      "metadata": {
        "id": "scdThsNA8T2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_mean_G(A_mdp, A_terminal, Agent(A_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfwvUi0VmiOZ",
        "outputId": "012b499d-e303-4cfb-b5d7-4631645c716d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9000000000000001"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_mean_G(B_mdp, B_terminal, Agent(B_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-Tc4Tp-mvo5",
        "outputId": "55534971-177c-454e-8829-5ab04b3cd7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21145559145703013"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_mean_G(C_mdp, C_terminal, Agent(C_actions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1L-5SbLaJFp",
        "outputId": "d1d4f892-2eb6-451c-bea4-1fc0d86e9d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3771629258981959"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEwRQRrZaMYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}